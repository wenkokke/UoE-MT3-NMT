Inuktitut English dataset configuration
vocab size, en=9363, fr=64858
in_en_model_50000/train_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/seq2seq_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.model
here False
not creating buckets as requested. will crash if buckets not present
finished training on 45000 sentences
--------------------------------------------------
computing perplexity
--------------------------------------------------
dev perplexity | 127.055770
# words in dev |   3331
--------------------------------------------------
Saving model
Finished saving model
wooohooo!
in_en_model_50000/train_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/dev_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/seq2seq_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN_1.model
BLEU: 10.45
finished training on 45000 sentences
--------------------------------------------------
computing perplexity
--------------------------------------------------
dev perplexity | 103.435643
# words in dev |   3331
--------------------------------------------------
Saving model
Finished saving model
wooohooo!
in_en_model_50000/train_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/dev_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/seq2seq_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN_2.model
finished training on 45000 sentences
--------------------------------------------------
computing perplexity
--------------------------------------------------
dev perplexity | 91.162664
# words in dev |   3331
--------------------------------------------------
Saving model
Finished saving model
wooohooo!
in_en_model_50000/train_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/dev_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/seq2seq_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN_3.model
BLEU: 11.25
finished training on 45000 sentences
--------------------------------------------------
computing perplexity
--------------------------------------------------
dev perplexity | 86.748713
# words in dev |   3331
--------------------------------------------------
Saving model
Finished saving model
wooohooo!
in_en_model_50000/train_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/dev_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/seq2seq_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN_4.model
finished training on 45000 sentences
--------------------------------------------------
computing perplexity
--------------------------------------------------
dev perplexity | 73.288273
# words in dev |   3331
--------------------------------------------------
Saving model
Finished saving model
wooohooo!
in_en_model_50000/train_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/dev_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/seq2seq_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN_5.model
BLEU: 13.08
finished training on 45000 sentences
--------------------------------------------------
computing perplexity
--------------------------------------------------
dev perplexity | 68.069064
# words in dev |   3331
--------------------------------------------------
Saving model
Finished saving model
wooohooo!
in_en_model_50000/train_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/dev_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/seq2seq_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN_6.model
finished training on 45000 sentences
--------------------------------------------------
computing perplexity
--------------------------------------------------
dev perplexity | 62.344054
# words in dev |   3331
--------------------------------------------------
Saving model
Finished saving model
wooohooo!
in_en_model_50000/train_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/dev_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/seq2seq_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN_7.model
BLEU: 11.14
finished training on 45000 sentences
--------------------------------------------------
computing perplexity
--------------------------------------------------
dev perplexity | 75.073832
# words in dev |   3331
--------------------------------------------------
Saving model
Finished saving model
wooohooo!
in_en_model_50000/train_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/dev_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/seq2seq_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN_8.model
finished training on 45000 sentences
--------------------------------------------------
computing perplexity
--------------------------------------------------
dev perplexity | 65.124848
# words in dev |   3331
--------------------------------------------------
Saving model
Finished saving model
wooohooo!
in_en_model_50000/train_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/dev_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/seq2seq_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN_9.model
BLEU: 12.51
finished training on 45000 sentences
--------------------------------------------------
computing perplexity
--------------------------------------------------
dev perplexity | 73.187946
# words in dev |   3331
--------------------------------------------------
Saving model
Finished saving model
wooohooo!
in_en_model_50000/train_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/dev_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/seq2seq_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN_10.model
finished training on 45000 sentences
--------------------------------------------------
computing perplexity
--------------------------------------------------
dev perplexity | 82.250034
# words in dev |   3331
--------------------------------------------------
Saving model
Finished saving model
wooohooo!
in_en_model_50000/train_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/dev_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/seq2seq_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN_11.model
BLEU: 12.64
finished training on 45000 sentences
--------------------------------------------------
computing perplexity
--------------------------------------------------
dev perplexity | 100.903338
# words in dev |   3331
--------------------------------------------------
Saving model
Finished saving model
wooohooo!
in_en_model_50000/train_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/dev_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/seq2seq_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN_12.model
finished training on 45000 sentences
--------------------------------------------------
computing perplexity
--------------------------------------------------
dev perplexity | 116.974077
# words in dev |   3331
--------------------------------------------------
Saving model
Finished saving model
wooohooo!
in_en_model_50000/train_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/dev_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/seq2seq_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN_13.model
BLEU: 16.81
finished training on 45000 sentences
--------------------------------------------------
computing perplexity
--------------------------------------------------
dev perplexity | 174.174568
# words in dev |   3331
--------------------------------------------------
Saving model
Finished saving model
wooohooo!
in_en_model_50000/train_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/dev_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/seq2seq_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN_14.model
finished training on 45000 sentences
--------------------------------------------------
computing perplexity
--------------------------------------------------
dev perplexity | 114.283337
# words in dev |   3331
--------------------------------------------------
Saving model
Finished saving model
wooohooo!
in_en_model_50000/train_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/dev_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/seq2seq_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN_15.model
BLEU: 18.99
Simple predictions (╯°□°）╯︵ ┻━┻
training set predictions
English predictions, s=0, num=2:
--------------------------------------------------
sentence: 0
Src | hansard                                                                         
Ref | hansard                                                                         
Hyp | iqaluit nunavut contents 0h0 nunavut nunavut nunavut nunavut nunavut nunavut _EOS
--------------------------------------------------
precision | 0.0000
recall | 0.0000
--------------------------------------------------
sentence: 1
Src | nunavut kanata                                                                  
Ref | nunavut canada                                                                  
Hyp | nunavut nunavut nunavut nunavut the nunavut nunavut nunavut of nunavut _EOS     
--------------------------------------------------
precision | 0.1000
recall | 0.5000
sentences matching filter = 2
Simple predictions (╯°□°）╯︵ ┻━┻
dev set predictions
English predictions, s=45000, num=3:
--------------------------------------------------
sentence: 45000
Src | isumajunga minisitaujuq tunisijunnarpa uvattinnut ilanginnik uattiarurnisavinirnik ammalu qanuilijjutigijanginnik tamatumunga ilaguttiutijausimajumut akilirsuinnariaqarutinginnut tamanna pitaqariaqalaurmat kiinaujanik ammalu aulattiutinginnik titirarvingmi
Ref | i wonder if the minister can give us some background and rationale for this additional expenditure that is required for finance and administration
Hyp | i don mr minister minister minister minister are are are background for for are these _EOS
--------------------------------------------------
precision | 0.3333
recall | 0.2174
--------------------------------------------------
sentence: 45001
Src | qujannamiingujutit                                                              
Ref | thank you                                                                       
Hyp | thank you mr thank thank thank thank you you you you _EOS                       
--------------------------------------------------
precision | 0.1818
recall | 1.0000
--------------------------------------------------
sentence: 45002
Src | iksivautaq tusaajikkut                                                          
Ref | chairperson interpretation                                                      
Hyp | chairperson interpretation interpretation interpretation interpretation interpretation interpretation interpretation interpretation interpretation interpretation interpretation interpretation interpretation interpretation interpretation interpretation interpretation interpretation _EOS
--------------------------------------------------
precision | 0.1053
recall | 1.0000
sentences matching filter = 3
--------------------------------------------------
BLEU: 18.99
--------------------------------------------------
Final saving model
Finished saving model
in_en_model_50000/train_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/dev_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.log
in_en_model_50000/seq2seq_50000sen_3-3layers_200units_base1_aajuq_SOFT_ATTN.model
BLEU: 18.99
